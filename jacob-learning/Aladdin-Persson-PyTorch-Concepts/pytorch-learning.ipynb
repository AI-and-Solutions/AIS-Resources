{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook on AP's video tutorial\n",
    "\n",
    "This is the first time im choosing to use a jupyter notebook, but I think its going to go really well for this style of coding. I'm excited actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing torch to use the PyTorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "built some tensors, the main datastructure used in machine learning. The tensor datastructure has a few cool arguments\n",
    "- first one is the matrix\n",
    "- second one is the datatype of the elements\n",
    "- third one specifies a device. This can be the GPU (cuda) or the CPU (default)\n",
    "- fourth one specifies if this tensor requires an *autograd*, pytorch's backpropagation algorithm\n",
    "\n",
    "by convention, you specify the device as \n",
    "```python\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "```\n",
    "\n",
    "as this automatically handles the decision as the resource is available on a user's machine.\n",
    "\n",
    "tensor objects have a stylized print method too, which is cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "\n",
      "backprop tensor:   tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], requires_grad=True)\n",
      "backprop tensor device:   cpu\n",
      "backprop tensor shape:   torch.Size([2, 3])\n",
      "backprop tensor datatype:   torch.float32\n"
     ]
    }
   ],
   "source": [
    "my_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "int_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "float_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "cuda_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=my_device)\n",
    "backprop_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=my_device, requires_grad=True)\n",
    "\n",
    "print(int_tensor)\n",
    "print(float_tensor)\n",
    "print(\"\\n\")\n",
    "print(\"backprop tensor:  \", backprop_tensor)\n",
    "print(\"backprop tensor device:  \",backprop_tensor.device)\n",
    "print(\"backprop tensor shape:  \",backprop_tensor.shape)\n",
    "print(\"backprop tensor datatype:  \",backprop_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other ways you can initialize a tensor\n",
    "- ```torch.empty()``` uses garbage memory. dont use this unless you know what you're doing\n",
    "- ```torch.zeros()``` initializes all elements of the tensor\n",
    "- ``torch.rand()`` initializes elements with values picked from a normal distribution\n",
    "- `torch.ones()` is pretty obvious, like zeroes\n",
    "- ```torch.eye()``` creates an identity matrix. note its size arguments are not inside a tuple\n",
    "- build a range of values with ```torch.arange()``` from start to end, by incrementing step value\n",
    "- build another range with `torch.linspace()` from start to end, but steps determines the number of entries and evenly increments all elements\n",
    "\n",
    "- `torch.diag(torch.some-tensor)` preserves values along the diagonal of the tensor argument, like multiplying with an identity matrix\n",
    "\n",
    "- `torch.uniform()` uses a uniform dist instead of norm\n",
    "\n",
    "you can also chain these initialization statements, like building the tensor with garbage memory and a fixed size, then calling .rand() on it. note that when calling the second function, convention has you place an underscore before the \"()\"\n",
    "\n",
    "```python\n",
    "x = torch.empty(size=(1,5)).normal_(mean=0, std=1)\n",
    "```\n",
    "note the underscore after normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sequences\n",
      "\n",
      "sequence A:\n",
      " tensor([0, 1, 2, 3, 4])\n",
      "sequence B:\n",
      " tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n",
      "diagonal:\n",
      " tensor([0.5629, 0.6385, 0.3835])\n",
      "chaining:\n",
      " tensor([[0.8776, 0.0230, 0.3836],\n",
      "        [0.7094, 0.8987, 0.8067],\n",
      "        [0.7813, 0.7041, 0.2490]])\n",
      "more chaining:\n",
      " tensor([[ 0.5210,  0.7509, -0.7612, -1.3762, -0.5968]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(size = (3, 3))\n",
    "y = torch.zeros((3, 3)) #size not needed to be specified\n",
    "z = torch.rand((3, 3))\n",
    "ones = torch.ones((3, 3))\n",
    "i = torch.eye(5, 5)\n",
    " \n",
    "sequence = torch.arange(start=0, end=5, step=1)\n",
    "other_sequence = torch.linspace(start=0.1, end=1, steps=10)\n",
    "\n",
    "\n",
    "''' \n",
    "\n",
    "print(\"empty array is composed of garbage memory:\\n\", x)\n",
    "print(\"zeroes array is initialized zeroes:\\n\", y)\n",
    "print(\"random array picks values from a norm dist:\\n\", z)\n",
    "print(\"ones is pretty obvious:\\n\", ones)\n",
    "print(\"i is the identity matrix. used in lin alg:\\n\", i)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "print('\\nsequences\\n')\n",
    "print(\"sequence A:\\n\", sequence)\n",
    "print(\"sequence B:\\n\", other_sequence)\n",
    "\n",
    "print(\"diagonal:\\n\", torch.diag(torch.rand((3, 3))))\n",
    "print(\"chaining:\\n\", torch.empty(size=(3,3)).uniform_(0,1))\n",
    "print(\"more chaining:\\n\", torch.empty(size=(1,5)).normal_(mean=0, std=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
